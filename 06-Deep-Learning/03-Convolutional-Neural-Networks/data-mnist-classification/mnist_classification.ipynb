{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "MZ_4ivRCaNfg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KKhR1xz7sjJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc38504-b217-49a4-995c-23c48f31a30d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Le Wagon 2024/Deep learning/03-Convolutional-Neural-Networks/data-mnist-classification\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eEVPYnQuJhS",
        "outputId": "036d4062-7d9f-492b-983d-47e00620430a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Le Wagon 2024/Deep learning/03-Convolutional-Neural-Networks/data-mnist-classification\n",
            "mnist_classification.ipynb  README.md  recognition.gif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woJFvjHqSf93"
      },
      "source": [
        "# MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0y29XMUSf97"
      },
      "source": [
        "üéØ <b><u>Exercise objectives</u></b>\n",
        "- Understand the *MNIST* dataset\n",
        "- Design your first **Convolutional Neural Network** (*CNN*) and answer questions such as:\n",
        "    - what are *Convolutional Layers*?\n",
        "    - how many *parameters* are involved in such a layer?\n",
        "- Train this CNN on images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB8-0k-FSf99"
      },
      "source": [
        "üöÄ <b><u>Let's get started!</u></b>\n",
        "\n",
        "Imagine that we are  back in time into the 90's.\n",
        "You work at a *Post Office* and you have to deal with an enormous amount of letters on a daily basis. How could you automate the process of reading the ZIP Codes, which are a combination of 5 handwritten digits?\n",
        "\n",
        "This task, called the **Handwriting Recognition**, used to be a very complex problem back in those days. It was solved by *Bell Labs* (among others) where one of the Deep Learning gurus, [*Yann Le Cun*](https://en.wikipedia.org/wiki/Yann_LeCun), used to work.\n",
        "\n",
        "From [Wikipedia](https://en.wikipedia.org/wiki/Handwriting_recognition):\n",
        "\n",
        "> Handwriting recognition (HWR), also known as Handwritten Text Recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrvQtIhySf99"
      },
      "source": [
        "![Number recognition](recognition.gif)\n",
        "\n",
        "*Note: The animation above is just here to help you visualize what happens with the different images: <br/> $\\rightarrow$ For each image, once the CNN is trained, it will predict what digit is written. The inputs are the different digits and not one animation/video!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz_wEgqaSf9-"
      },
      "source": [
        "ü§î <b><u>How does this CNN work ?</u></b>\n",
        "\n",
        "- *Inputs*: Images (_each image shows a handwritten digit_)\n",
        "- *Target*: For each image, you want your CNN model to predict the correct digit (between 0 and 9)\n",
        "    - It is a **multi-class classification** task (more precisely a 10-class classification task since there are 10 different digits).\n",
        "\n",
        "üî¢ To improve the capacity of the Convolutional Neural Network to read these numbers, we need to feed it with many images representing handwritten digits. This is why the üìö [**MNIST dataset**](http://yann.lecun.com/exdb/mnist/) *(Mixed National Institute of Standards and Technology)* was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gh7MWrYrSf9-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmlENO_1Sf-A"
      },
      "source": [
        "## (1) The `MNIST` Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGN3Du5USf-A"
      },
      "source": [
        "üìö Tensorflow/Keras offers multiple [**datasets**](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to play with:\n",
        "- *Vectors*: `boston_housing` (regression)\n",
        "- *Images* : `mnist`, `fashion_mnist`, `cifar10`, `cifar100` (classification)\n",
        "- *Texts*: `imbd`, `reuters` (classification/sentiment analysis)\n",
        "\n",
        "\n",
        "üíæ You can **load the MNIST dataset** with the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBvJGazBSf-A",
        "outputId": "a2864bde-da5a-48d8-d15e-68ad7ea55563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from tensorflow.keras import datasets\n",
        "\n",
        "\n",
        "# Loading the MNIST Dataset...\n",
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "\n",
        "# The train set contains 60 000 images, each of them of size 28x28\n",
        "# The test set contains 10 000 images, each of them of size 28x28\n",
        "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnoNaMktSf-B"
      },
      "source": [
        "### (1.1) Exploring the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMtwtB78Sf-B"
      },
      "source": [
        "‚ùì **Question: Let's have look at some handwritten digits of this MNIST dataset.** ‚ùì\n",
        "\n",
        "üñ® Print some images from the *train set*.\n",
        "\n",
        "<details>\n",
        "    <summary><i>Hints</i></summary>\n",
        "\n",
        "üí°*Hint*: use the `imshow` function from `matplotlib` with `cmap = \"gray\"`\n",
        "\n",
        "ü§® Note: if you don't specify this *cmap* argument, the weirdly displayed colors are just Matplotlib defaults...\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "L7Ov3H4ASf-B",
        "outputId": "6fadc186-289e-4420-f4c5-327b1fa1842d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x784ac7652020>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAb2klEQVR4nO3df2xV9f3H8dct0gtKe1mp7e2VHxYEWUTKZNA1IqI0QHUGlCzIyMTF6HDFKExcuvDLzaQbc8xpGJpsgxkFmdsAMRlGCy2ZKzh+hZhtDSXdWkJbpBn3liKFtJ/vH/1655UWPJd7ebeX5yP5JL3nnHfPm8Phvjj3nvu5PuecEwAAV1madQMAgGsTAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAAT11k38EWdnZ06ceKEMjIy5PP5rNsBAHjknFNra6tCoZDS0nq+zul1AXTixAkNGzbMug0AwBVqaGjQ0KFDe1zf616Cy8jIsG4BAJAAl3s+T1oArVu3TjfffLMGDBigwsJCffTRR1+qjpfdACA1XO75PCkBtGXLFi1dulSrVq3SwYMHVVBQoJkzZ+rkyZPJ2B0AoC9ySTB58mRXWloafdzR0eFCoZArLy+/bG04HHaSGAwGg9HHRzgcvuTzfcKvgM6fP68DBw6ouLg4uiwtLU3FxcWqrq6+aPv29nZFIpGYAQBIfQkPoFOnTqmjo0O5ubkxy3Nzc9XU1HTR9uXl5QoEAtHBHXAAcG0wvwuurKxM4XA4OhoaGqxbAgBcBQn/HFB2drb69eun5ubmmOXNzc0KBoMXbe/3++X3+xPdBgCgl0v4FVB6eromTpyoioqK6LLOzk5VVFSoqKgo0bsDAPRRSZkJYenSpVq4cKG+/vWva/LkyXrppZfU1tam7373u8nYHQCgD0pKAM2bN0+ffPKJVq5cqaamJk2YMEE7d+686MYEAMC1y+ecc9ZNfF4kElEgELBuAwBwhcLhsDIzM3tcb34XHADg2kQAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABPXWTcA4MuZOHGi55rFixfHta9HHnnEc83rr7/uueaVV17xXHPw4EHPNeiduAICAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgwuecc9ZNfF4kElEgELBuA0iqCRMmeK7ZtWuX55rMzEzPNVdTOBz2XDNkyJAkdIJkCIfDlzwHuQICAJgggAAAJhIeQKtXr5bP54sZY8eOTfRuAAB9XFK+kO62227TBx988L+dXMf33gEAYiUlGa677joFg8Fk/GoAQIpIyntAR48eVSgU0siRI7VgwQLV19f3uG17e7sikUjMAACkvoQHUGFhoTZu3KidO3dq/fr1qqur01133aXW1tZuty8vL1cgEIiOYcOGJbolAEAvlPTPAZ0+fVojRozQ2rVr9dhjj120vr29Xe3t7dHHkUiEEELK43NAXfgcUGq73OeAkn53wODBgzVmzBjV1tZ2u97v98vv9ye7DQBAL5P0zwGdOXNGx44dU15eXrJ3BQDoQxIeQM8++6yqqqr073//W3/729/04IMPql+/fpo/f36idwUA6MMS/hLc8ePHNX/+fLW0tOjGG2/UlClTtHfvXt14442J3hUAoA9jMlLgCk2ePNlzzZ/+9CfPNaFQyHNNvP+8e7pr9VLOnz/vuSaeGwqmTJniuebgwYOea6T4/kz4HyYjBQD0SgQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwk/QvpAAvXX399XHV33HGH55o33njDc01v/36so0ePeq5Zs2aN55q33nrLc82HH37ouWb58uWeaySpvLw8rjp8OVwBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMMBs2UtJrr70WV938+fMT3EnfFM+s4IMGDfJcU1VV5blm2rRpnmvGjx/vuQbJxxUQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE0xGil5v4sSJnmvuv//+uPbl8/niqvMqnkk4d+zY4bnmxRdf9FwjSSdOnPBcc+jQIc81//3vfz3X3HvvvZ5rrtbfK7zhCggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJn3POWTfxeZFIRIFAwLoNJMmECRM81+zatctzTWZmpueaeP3lL3/xXDN//nzPNXfffbfnmvHjx3uukaTf/OY3nms++eSTuPblVUdHh+eas2fPxrWveI75wYMH49pXKgqHw5f8t8gVEADABAEEADDhOYD27NmjBx54QKFQSD6fT9u2bYtZ75zTypUrlZeXp4EDB6q4uFhHjx5NVL8AgBThOYDa2tpUUFCgdevWdbt+zZo1evnll/Xqq69q3759uuGGGzRz5kydO3fuipsFAKQOz9+IWlJSopKSkm7XOef00ksvafny5Zo9e7Yk6fXXX1dubq62bdumhx9++Mq6BQCkjIS+B1RXV6empiYVFxdHlwUCARUWFqq6urrbmvb2dkUikZgBAEh9CQ2gpqYmSVJubm7M8tzc3Oi6LyovL1cgEIiOYcOGJbIlAEAvZX4XXFlZmcLhcHQ0NDRYtwQAuAoSGkDBYFCS1NzcHLO8ubk5uu6L/H6/MjMzYwYAIPUlNIDy8/MVDAZVUVERXRaJRLRv3z4VFRUlclcAgD7O811wZ86cUW1tbfRxXV2dDh8+rKysLA0fPlzPPPOMXnjhBY0ePVr5+flasWKFQqGQ5syZk8i+AQB9nOcA2r9/v+65557o46VLl0qSFi5cqI0bN+q5555TW1ubnnjiCZ0+fVpTpkzRzp07NWDAgMR1DQDo85iMFHEbM2aM55pVq1Z5ronn82OnTp3yXCNJjY2NnmteeOEFzzV//OMfPdegSzyTkcb7NLdlyxbPNQsWLIhrX6mIyUgBAL0SAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMCE569jQOrx+/1x1b344ouea+677z7PNa2trZ5rHnnkEc81UtfXjXg1cODAuPaF3m/48OHWLaQ0roAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYYDJS6Gtf+1pcdfFMLBqP2bNne66pqqpKQicAEokrIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACaYjBRau3ZtXHU+n89zTTyThDKxKD4vLc37/5s7OzuT0AmuFFdAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATDAZaYr55je/6blmwoQJce3LOee55p133olrX8Bn4plYNJ5zVZIOHz4cVx2+HK6AAAAmCCAAgAnPAbRnzx498MADCoVC8vl82rZtW8z6Rx99VD6fL2bMmjUrUf0CAFKE5wBqa2tTQUGB1q1b1+M2s2bNUmNjY3Rs3rz5ipoEAKQezzchlJSUqKSk5JLb+P1+BYPBuJsCAKS+pLwHVFlZqZycHN1666168skn1dLS0uO27e3tikQiMQMAkPoSHkCzZs3S66+/roqKCv3sZz9TVVWVSkpK1NHR0e325eXlCgQC0TFs2LBEtwQA6IUS/jmghx9+OPrz7bffrvHjx2vUqFGqrKzU9OnTL9q+rKxMS5cujT6ORCKEEABcA5J+G/bIkSOVnZ2t2trabtf7/X5lZmbGDABA6kt6AB0/flwtLS3Ky8tL9q4AAH2I55fgzpw5E3M1U1dXp8OHDysrK0tZWVl6/vnnNXfuXAWDQR07dkzPPfecbrnlFs2cOTOhjQMA+jbPAbR//37dc8890cefvX+zcOFCrV+/XkeOHNHvf/97nT59WqFQSDNmzNBPfvIT+f3+xHUNAOjzPAfQtGnTLjmx33vvvXdFDeHKDBw40HNNenp6XPs6efKk55otW7bEtS/0fvH8J3P16tWJb6Qbu3btiquurKwswZ3g85gLDgBgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgIuFfyY1rR3t7u+eaxsbGJHSCRItnZuvly5d7rlm2bJnnmuPHj3uu+cUvfuG5Rur6/jMkD1dAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATDAZKeL2zjvvWLeAy5gwYUJcdfFMEjpv3jzPNdu3b/dcM3fuXM816J24AgIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCyUhTjM/nuyo1kjRnzhzPNU8//XRc+4K0ZMkSzzUrVqyIa1+BQMBzzZtvvum55pFHHvFcg9TBFRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATTEaaYpxzV6VGkoLBoOeal19+2XPN7373O881LS0tnmsk6Rvf+Ibnmu985zueawoKCjzXDB061HNNfX295xpJeu+99zzX/PrXv45rX7h2cQUEADBBAAEATHgKoPLyck2aNEkZGRnKycnRnDlzVFNTE7PNuXPnVFpaqiFDhmjQoEGaO3eumpubE9o0AKDv8xRAVVVVKi0t1d69e/X+++/rwoULmjFjhtra2qLbLFmyRDt27NDbb7+tqqoqnThxQg899FDCGwcA9G2ebkLYuXNnzOONGzcqJydHBw4c0NSpUxUOh/Xb3/5WmzZt0r333itJ2rBhg7761a9q7969cb3BCwBITVf0HlA4HJYkZWVlSZIOHDigCxcuqLi4OLrN2LFjNXz4cFVXV3f7O9rb2xWJRGIGACD1xR1AnZ2deuaZZ3TnnXdq3LhxkqSmpialp6dr8ODBMdvm5uaqqamp299TXl6uQCAQHcOGDYu3JQBAHxJ3AJWWlurjjz/WW2+9dUUNlJWVKRwOR0dDQ8MV/T4AQN8Q1wdRFy9erHfffVd79uyJ+XBcMBjU+fPndfr06ZiroObm5h4/tOj3++X3++NpAwDQh3m6AnLOafHixdq6dat27dql/Pz8mPUTJ05U//79VVFREV1WU1Oj+vp6FRUVJaZjAEBK8HQFVFpaqk2bNmn79u3KyMiIvq8TCAQ0cOBABQIBPfbYY1q6dKmysrKUmZmpp556SkVFRdwBBwCI4SmA1q9fL0maNm1azPINGzbo0UcflST98pe/VFpamubOnav29nbNnDmTOaIAABfxuXhnokySSCSiQCBg3Uaf9a1vfctzzebNm5PQSeLEM5NGvLfzjx49Oq66q6GnjzJcyu7du+Pa18qVK+OqAz4vHA4rMzOzx/XMBQcAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMBHXN6Ki94pnxuS///3vce1r0qRJcdV51dO36V5Kbm5uEjrpXktLi+eaeL7K/umnn/ZcA/RmXAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAw4XPOOesmPi8SiSgQCFi3cU3Jy8uLq+573/ue55rly5d7rvH5fJ5r4j2tf/WrX3muWb9+veea2tpazzVAXxMOh5WZmdnjeq6AAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmGAyUgBAUjAZKQCgVyKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAlPAVReXq5JkyYpIyNDOTk5mjNnjmpqamK2mTZtmnw+X8xYtGhRQpsGAPR9ngKoqqpKpaWl2rt3r95//31duHBBM2bMUFtbW8x2jz/+uBobG6NjzZo1CW0aAND3Xedl4507d8Y83rhxo3JycnTgwAFNnTo1uvz6669XMBhMTIcAgJR0Re8BhcNhSVJWVlbM8jfffFPZ2dkaN26cysrKdPbs2R5/R3t7uyKRSMwAAFwDXJw6Ojrc/fff7+68886Y5a+99prbuXOnO3LkiHvjjTfcTTfd5B588MEef8+qVaucJAaDwWCk2AiHw5fMkbgDaNGiRW7EiBGuoaHhkttVVFQ4Sa62trbb9efOnXPhcDg6GhoazA8ag8FgMK58XC6APL0H9JnFixfr3Xff1Z49ezR06NBLbltYWChJqq2t1ahRoy5a7/f75ff742kDANCHeQog55yeeuopbd26VZWVlcrPz79szeHDhyVJeXl5cTUIAEhNngKotLRUmzZt0vbt25WRkaGmpiZJUiAQ0MCBA3Xs2DFt2rRJ9913n4YMGaIjR45oyZIlmjp1qsaPH5+UPwAAoI/y8r6Penidb8OGDc455+rr693UqVNdVlaW8/v97pZbbnHLli277OuAnxcOh81ft2QwGAzGlY/LPff7/j9Yeo1IJKJAIGDdBgDgCoXDYWVmZva4nrngAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmel0AOeesWwAAJMDlns97XQC1trZatwAASIDLPZ/7XC+75Ojs7NSJEyeUkZEhn88Xsy4SiWjYsGFqaGhQZmamUYf2OA5dOA5dOA5dOA5desNxcM6ptbVVoVBIaWk9X+dcdxV7+lLS0tI0dOjQS26TmZl5TZ9gn+E4dOE4dOE4dOE4dLE+DoFA4LLb9LqX4AAA1wYCCABgok8FkN/v16pVq+T3+61bMcVx6MJx6MJx6MJx6NKXjkOvuwkBAHBt6FNXQACA1EEAAQBMEEAAABMEEADARJ8JoHXr1unmm2/WgAEDVFhYqI8++si6patu9erV8vl8MWPs2LHWbSXdnj179MADDygUCsnn82nbtm0x651zWrlypfLy8jRw4EAVFxfr6NGjNs0m0eWOw6OPPnrR+TFr1iybZpOkvLxckyZNUkZGhnJycjRnzhzV1NTEbHPu3DmVlpZqyJAhGjRokObOnavm5majjpPjyxyHadOmXXQ+LFq0yKjj7vWJANqyZYuWLl2qVatW6eDBgyooKNDMmTN18uRJ69auuttuu02NjY3R8de//tW6paRra2tTQUGB1q1b1+36NWvW6OWXX9arr76qffv26YYbbtDMmTN17ty5q9xpcl3uOEjSrFmzYs6PzZs3X8UOk6+qqkqlpaXau3ev3n//fV24cEEzZsxQW1tbdJslS5Zox44devvtt1VVVaUTJ07ooYceMuw68b7McZCkxx9/POZ8WLNmjVHHPXB9wOTJk11paWn0cUdHhwuFQq68vNywq6tv1apVrqCgwLoNU5Lc1q1bo487OztdMBh0P//5z6PLTp8+7fx+v9u8ebNBh1fHF4+Dc84tXLjQzZ4926QfKydPnnSSXFVVlXOu6+++f//+7u23345u889//tNJctXV1VZtJt0Xj4Nzzt19993u6aeftmvqS+j1V0Dnz5/XgQMHVFxcHF2Wlpam4uJiVVdXG3Zm4+jRowqFQho5cqQWLFig+vp665ZM1dXVqampKeb8CAQCKiwsvCbPj8rKSuXk5OjWW2/Vk08+qZaWFuuWkiocDkuSsrKyJEkHDhzQhQsXYs6HsWPHavjw4Sl9PnzxOHzmzTffVHZ2tsaNG6eysjKdPXvWor0e9brJSL/o1KlT6ujoUG5ubszy3Nxc/etf/zLqykZhYaE2btyoW2+9VY2NjXr++ed111136eOPP1ZGRoZ1eyaampokqdvz47N114pZs2bpoYceUn5+vo4dO6Yf/ehHKikpUXV1tfr162fdXsJ1dnbqmWee0Z133qlx48ZJ6jof0tPTNXjw4JhtU/l86O44SNK3v/1tjRgxQqFQSEeOHNEPf/hD1dTU6M9//rNht7F6fQDhf0pKSqI/jx8/XoWFhRoxYoT+8Ic/6LHHHjPsDL3Bww8/HP359ttv1/jx4zVq1ChVVlZq+vTphp0lR2lpqT7++ONr4n3QS+npODzxxBPRn2+//Xbl5eVp+vTpOnbsmEaNGnW12+xWr38JLjs7W/369bvoLpbm5mYFg0GjrnqHwYMHa8yYMaqtrbVuxcxn5wDnx8VGjhyp7OzslDw/Fi9erHfffVe7d++O+fqWYDCo8+fP6/Tp0zHbp+r50NNx6E5hYaEk9arzodcHUHp6uiZOnKiKioross7OTlVUVKioqMiwM3tnzpzRsWPHlJeXZ92Kmfz8fAWDwZjzIxKJaN++fdf8+XH8+HG1tLSk1PnhnNPixYu1detW7dq1S/n5+THrJ06cqP79+8ecDzU1Naqvr0+p8+Fyx6E7hw8flqTedT5Y3wXxZbz11lvO7/e7jRs3un/84x/uiSeecIMHD3ZNTU3WrV1VP/jBD1xlZaWrq6tzH374oSsuLnbZ2dnu5MmT1q0lVWtrqzt06JA7dOiQk+TWrl3rDh065P7zn/8455z76U9/6gYPHuy2b9/ujhw54mbPnu3y8/Pdp59+atx5Yl3qOLS2trpnn33WVVdXu7q6OvfBBx+4O+64w40ePdqdO3fOuvWEefLJJ10gEHCVlZWusbExOs6ePRvdZtGiRW748OFu165dbv/+/a6oqMgVFRUZdp14lzsOtbW17sc//rHbv3+/q6urc9u3b3cjR450U6dONe48Vp8IIOece+WVV9zw4cNdenq6mzx5stu7d691S1fdvHnzXF5enktPT3c33XSTmzdvnqutrbVuK+l2797tJF00Fi5c6JzruhV7xYoVLjc31/n9fjd9+nRXU1Nj23QSXOo4nD171s2YMcPdeOONrn///m7EiBHu8ccfT7n/pHX355fkNmzYEN3m008/dd///vfdV77yFXf99de7Bx980DU2Nto1nQSXOw719fVu6tSpLisry/n9fnfLLbe4ZcuWuXA4bNv4F/B1DAAAE73+PSAAQGoigAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABg4v8Ahi/pwYYPKekAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(X_train[1], cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkuWFa76Sf-C"
      },
      "source": [
        "### (1.2) Image Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLQcoNvoSf-C"
      },
      "source": [
        "‚ùóÔ∏è **Neural Networks converge faster when the input data is somehow normalized** ‚ùóÔ∏è\n",
        "\n",
        "üë©üèª‚Äçüè´ How do we proceed for Convolutional Neural Networks ?\n",
        "* The `RBG` intensities are coded between 0 and 255.\n",
        "* We can simply divide the input data by the maximal value 255 to have all the pixels' intensities between 0 and 1 üòâ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMPLbwEcSf-C"
      },
      "source": [
        "‚ùì **Question ‚ùì As a first preprocessing step, please normalize your data.**\n",
        "\n",
        "Don't forget to do it both on your train data and your test data.\n",
        "\n",
        "(*Note: you can also center your data, by subtracting 0.5 from all the values, but it is not mandatory*)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "metadata": {
        "id": "FIEaJWX-ZH7W"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9J4jiEwSf-C"
      },
      "source": [
        "### (1.3) Inputs' dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYD7DwqKSf-D",
        "outputId": "ff3d2ee2-59a9-4cc6-9ed2-85b65e0b197c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKjhfodcSf-D"
      },
      "source": [
        "üëÜ Remember that you have 60,000 training images and 10,000 test images, each of size $(28, 28)$. However...\n",
        "\n",
        "> ‚ùóÔ∏è  **`Convolutional Neural Network models need to be fed with images whose last dimension is the number of channels`.**  \n",
        "\n",
        "> üßëüèª‚Äçüè´ The shape of tensors fed into ***ConvNets*** is the following: `(NUMBER_OF_IMAGES, HEIGHT, WIDTH, CHANNELS)`\n",
        "\n",
        "üïµüèªThis last dimension is clearly missing here. Can you guess the reason why?\n",
        "<br>\n",
        "<details>\n",
        "    <summary><i>Answer<i></summary>\n",
        "        \n",
        "* All these $60000$ $ (28 \\times 28) $ pictures are black-and-white $ \\implies $ Each pixel lives on a spectrum from full black (0) to full white (1).\n",
        "        \n",
        "    * Theoretically, you don't need to know the number of channels for a black-and-white picture since there is only 1 channel (the \"whiteness\" of \"blackness\" of a pixel). However, it is still mandatory for the model to have this number of channels explicitly stated.\n",
        "        \n",
        "    * In comparison, colored pictures need multiple channels:\n",
        "        - the RGB system with 3 channels (<b><span style=\"color:red\">Red</span> <span style=\"color:green\">Green</span> <span style=\"color:blue\">Blue</span></b>)\n",
        "        - the CYMK system  with 4 channels (<b><span style=\"color:cyan\">Cyan</span> <span style=\"color:magenta\">Magenta</span> <span style=\"color:yellow\">Yellow</span> <span style=\"color:black\">Black</span></b>)\n",
        "        \n",
        "        \n",
        "</details>        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmPYi1ztSf-D"
      },
      "source": [
        "‚ùì **Question: expanding dimensions** ‚ùì\n",
        "\n",
        "* Use the **`expand_dims`** to add one dimension at the end of the training data and test data.\n",
        "\n",
        "* Then, print the shapes of `X_train` and `X_test`. They should respectively be equal to $(60000, 28, 28, 1)$ and $(10000, 28, 28, 1)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bUeOwTmQSf-D"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.backend import expand_dims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbR11Pl7Sf-D",
        "outputId": "1c128bbb-1779-484b-d2b3-0e9a9480adc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([60000, 28, 28, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X_train_expanded = expand_dims(X_train)\n",
        "X_train_expanded.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_expanded = expand_dims(X_test)\n",
        "X_test_expanded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cuecq7-ba0Wf",
        "outputId": "4a2a1331-7190-4f40-f662-8acbd0581208"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10000, 28, 28, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiN1_V7bSf-E"
      },
      "source": [
        "### (1.4) Target encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0LODN4PSf-E"
      },
      "source": [
        "One more thing to do for a multiclass classification task in Deep Leaning:\n",
        "\n",
        "üëâ _\"one-hot-encode\" the categories*_\n",
        "\n",
        "‚ùì **Question: encoding the labels** ‚ùì\n",
        "\n",
        "* Use **`to_categorical`** to transform your labels.\n",
        "* Store the results into two variables that you can call **`y_train_cat`** and **`y_test_cat`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JCp0DY7JSf-E"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aW5J-u3aSf-E"
      },
      "outputs": [],
      "source": [
        "# Quick check that you correctly used to_categorical\n",
        "assert(y_train_cat.shape == (60000,10))\n",
        "assert(y_test_cat.shape == (10000,10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crtG1wDmSf-E"
      },
      "source": [
        "The data is now ready to be used. ‚úÖ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV-uZs_LSf-E"
      },
      "source": [
        "## (2) The Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IeQ9LMjSf-E"
      },
      "source": [
        "### (2.1) Architecture and compilation of a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0aMNTi_Sf-F"
      },
      "source": [
        "\n",
        "‚ùì **Question: CNN Architecture and compilation** ‚ùì\n",
        "\n",
        "Now, let's build a <u>Convolutional Neural Network</u> that has:\n",
        "\n",
        "\n",
        "- a `Conv2D` layer with 8 filters, each of size $(4, 4)$, an input shape suitable for your task, the `relu` activation function, and `padding='same'`\n",
        "- a `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "- a second `Conv2D` layer with 16 filters, each of size $(3, 3)$, and the `relu` activation function\n",
        "- a second `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "\n",
        "\n",
        "- a `Flatten` layer\n",
        "- a first `Dense` layer with 10 neurons and the `relu` activation function\n",
        "- a last (predictive) layer that is suited for your task\n",
        "\n",
        "In the function that initializes this model, do not forget to include the <u>compilation of the model</u>, which:\n",
        "* optimizes the `categorical_crossentropy` loss function,\n",
        "* with the `adam` optimizer,\n",
        "* and the `accuracy` as the metrics\n",
        "\n",
        "(*Note: you could add more classification metrics if you want but the dataset is well balanced!*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "7g2wGFKFSf-F"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "\n",
        "def initialize_model():\n",
        "\n",
        "    model = models.Sequential()\n",
        "\n",
        "    ### First Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(8, (4,4), padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1)))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    ### Second Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(16, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    ### Flattening\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n",
        "    model.add(layers.Dense(10, activation=\"relu\"))\n",
        "\n",
        "    ### Last layer - Classification Layer with 10 outputs corresponding to 10 digits\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    ### Model compilation\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate params\n",
        "# filters * (channels * (kernel_dim_a * kerlnel_dim_b)) + n_filters\n",
        "\n",
        "params1 = 8 * (1 * (4*4)) + 8\n",
        "params2 = 16 * (8 * (3*3)) + 16\n",
        "flattening = 7*7*16\n",
        "params3 = flattening * 10 + 10\n",
        "params4 = 10 * 10 + 10\n",
        "\n",
        "params1 + params2 + params3 + params4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzzi0414fATj",
        "outputId": "31ea20a5-3e6c-4ae7-be31-42f0aafb8922"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9264"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1168 + 136"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upYHE2TA1IBj",
        "outputId": "c8cbee3c-879f-4407-87de-7b184e0c3d10"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1304"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params1 + params2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-XbY_sihjZi",
        "outputId": "3ba3a568-65ee-4dac-becf-88d74c391c4f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1304"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = initialize_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6MirPQHebCo",
        "outputId": "30a08c4f-218d-49f4-faa5-ecf547191ba4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 8)         136       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 14, 14, 8)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 14, 14, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 7, 7, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9264 (36.19 KB)\n",
            "Trainable params: 9264 (36.19 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uErpFen0Sf-F"
      },
      "source": [
        "‚ùì **Question: number of trainable parameters in a convolutional layer** ‚ùì\n",
        "\n",
        "How many trainable parameters are there in your model?\n",
        "1. Compute them with ***model.summary( )*** first\n",
        "2. Recompute them manually to make sure you properly understood ***what influences the number of weights in a CNN***."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "atYO86ZJSf-F"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_expanded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl6KJjPT34hv",
        "outputId": "4a4eadb1-a98d-4a07-f33c-728e5ce70cff"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([60000, 28, 28, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUWqFj6X37B4",
        "outputId": "1746097b-dd81-488d-d093-24fe2ea8820c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qUqOCkUSf-G"
      },
      "source": [
        "### (2.2) Training a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnLXXyxfSf-G"
      },
      "source": [
        "‚ùì **Question: training a CNN** ‚ùì\n",
        "\n",
        "Initialize your model and fit it on the train data.\n",
        "- Do not forget to use a **Validation Set/Split** and an **Early Stopping criterion**.\n",
        "- Limit yourself to 5 epochs max in this challenge, just to save some precious time for the more advanced challenges!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2MlfJODSf-G",
        "outputId": "8c9f8a3d-106f-4155-9a55-9b28722a1272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1313/1313 [==============================] - 30s 22ms/step - loss: 0.6291 - accuracy: 0.8020 - val_loss: 0.1787 - val_accuracy: 0.9477\n",
            "Epoch 2/5\n",
            "1313/1313 [==============================] - 27s 20ms/step - loss: 0.1435 - accuracy: 0.9579 - val_loss: 0.1157 - val_accuracy: 0.9651\n",
            "Epoch 3/5\n",
            "1313/1313 [==============================] - 27s 20ms/step - loss: 0.1029 - accuracy: 0.9695 - val_loss: 0.0970 - val_accuracy: 0.9696\n",
            "Epoch 4/5\n",
            "1313/1313 [==============================] - 28s 21ms/step - loss: 0.0814 - accuracy: 0.9758 - val_loss: 0.0849 - val_accuracy: 0.9739\n",
            "Epoch 5/5\n",
            "1313/1313 [==============================] - 28s 22ms/step - loss: 0.0710 - accuracy: 0.9781 - val_loss: 0.0791 - val_accuracy: 0.9757\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x784aa1f5dab0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "es = EarlyStopping(restore_best_weights=True)\n",
        "\n",
        "\n",
        "model = initialize_model()\n",
        "\n",
        "histroy = model.fit(X_train_expanded, y_train_cat, validation_split=0.3, callbacks=[es], epochs=5, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6DZaawgSf-G"
      },
      "source": [
        "‚ùì **Question: How many iterations does the CNN perform per epoch** ‚ùì\n",
        "\n",
        "_Note: it has nothing to do with the fact that this is a CNN. This is related to the concept of forward/backward propagation already covered during the previous lecture on optimizers, fitting, and losses üòâ_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "Pal87QOlSf-G"
      },
      "source": [
        "> YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF_bUIwySf-G"
      },
      "source": [
        "<details>\n",
        "    <summary><i>Answer</i></summary>\n",
        "\n",
        "With `verbose = 1` when fitting your model, you have access to crucial information about your training procedure.\n",
        "    \n",
        "Remember that we've just trained our CNN model on $60000$ training images\n",
        "\n",
        "If the chosen batch size is 32:\n",
        "\n",
        "* For each epoch, we have $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ minibatches <br/>\n",
        "* The _validation_split_ is equal to $0.3$ - which means that within one single epoch, there are:\n",
        "    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batches are used to compute the `train_loss`\n",
        "    * $ 1875 - 1312 = 562 $ batches are used to compute the `val_loss`\n",
        "    * **The parameters are updated 1313 times per epoch** as there are 1313 forward/backward propagations per epoch !!!\n",
        "\n",
        "\n",
        "üëâ With so many updates of the weights within one epoch, you can understand why this CNN model converges even with a limited number of epochs.\n",
        "\n",
        "</details>    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arLq8cA2Sf-K"
      },
      "source": [
        "### (2.3) Evaluating its performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23fohxfJSf-L"
      },
      "source": [
        "‚ùì **Question: Evaluating your CNN** ‚ùì\n",
        "\n",
        "What is your **`accuracy on the test set?`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raLbBvhISf-L",
        "outputId": "b9b307c7-d185-4247-e7c0-a564ce3e6d8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0664 - accuracy: 0.9792\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06644290685653687, 0.979200005531311]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "result = model.evaluate(X_test_expanded, y_test_cat)\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN31SMlVSf-L"
      },
      "source": [
        "üéâ You should already be impressed by your CNN skills! Reaching over 95% accuracy!\n",
        "\n",
        "üî• You solved what was a very hard problem 30 years ago with your own CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWkqtXqjSf-L"
      },
      "source": [
        "üèÅ **Congratulations!**\n",
        "\n",
        "üíæ Don't forget to `git add/commit/push` your notebook...\n",
        "\n",
        "üöÄ ... and move on to the next challenge!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}